{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd5b24f0",
   "metadata": {},
   "source": [
    "# Deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc010d7",
   "metadata": {},
   "source": [
    "## numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a24a3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e3f81af",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[1,2],[3,4],[5,6],[7,8]]\n",
    "b = np.array(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf86c85",
   "metadata": {},
   "source": [
    "### np.array(ARRAY)로 만들어진 것의 정체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8003aabc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b325457",
   "metadata": {},
   "source": [
    "b는 ndarray 객체다.  \n",
    "b 행렬의 특성을 알고 싶다면 메소드가 아닌 프로퍼티로 접근  \n",
    "=> b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60287bd5",
   "metadata": {},
   "source": [
    "## 넘파이 객체 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ab611e",
   "metadata": {},
   "source": [
    "### X = shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b0af5eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = np.zeros((3,4)) #.ones() .eye()\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbf5478",
   "metadata": {},
   "source": [
    "### X = about 등차수열\n",
    "불완전한 키워드를 왜 썼을까 arange, linspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18b1a8f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = np.arange(5)\n",
    "d\n",
    "# or np.arange(1, 10, 2) <= 시작, 끝, d 등차수열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e58dce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  1.11111111,  2.22222222,  3.33333333,  4.44444444,\n",
       "        5.55555556,  6.66666667,  7.77777778,  8.88888889, 10.        ])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 시작~끝을 n-1등분으로 표현, n개 결과값\n",
    "e = np.linspace(0,10,10)\n",
    "e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2686dcd",
   "metadata": {},
   "source": [
    "## 넘파이 객체 변형"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6790e2b",
   "metadata": {},
   "source": [
    "## Concatenate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8222119f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = np.array([[1,2],[3,4]])\n",
    "g = np.array([[5,6],[7,8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77933898",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38377808",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 6],\n",
       "       [7, 8]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee115ed8",
   "metadata": {},
   "source": [
    "### numpy식 array 표기에서 시작"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318478b1",
   "metadata": {},
   "source": [
    "axis = 0(행방향) -> 위아래 이어붙이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2738456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4],\n",
       "       [5, 6],\n",
       "       [7, 8]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate((f,g), axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70473413",
   "metadata": {},
   "source": [
    "axis = 1(열방향) -> 양옆 이어붙이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "665abcdb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 5, 6],\n",
       "       [3, 4, 7, 8]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate((f,g), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c057988",
   "metadata": {},
   "source": [
    "vstack -> vertical하게 쌓음  \n",
    "hstack -> horizontal하게 쌓음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5bbf6174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 5, 6],\n",
       "       [3, 4, 7, 8]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack((f,g))\n",
    "np.hstack((f,g))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebffe7ee",
   "metadata": {},
   "source": [
    "## Reshape()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea87f4d0",
   "metadata": {},
   "source": [
    "ndim 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9045e6cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = np.arange(8)\n",
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "376c836f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 3],\n",
       "       [4, 5, 6, 7]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = h.reshape(2,4)\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8fd2505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [2, 3],\n",
       "       [4, 5],\n",
       "       [6, 7]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = h.reshape(4,-1)\n",
    "k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd29881",
   "metadata": {},
   "source": [
    "### split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45e5c582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
       "       [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n",
       "       [30, 31, 32, 33, 34, 35, 36, 37, 38, 39]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = np.arange(10,40,1).reshape(-1,10)\n",
    "array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1e9f55",
   "metadata": {},
   "source": [
    "np.split(ARRAY, INDEX(index-1까지 커팅), AXIS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "405987ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10, 11, 12],\n",
       "       [20, 21, 22],\n",
       "       [30, 31, 32]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr1, arr2 = np.split(array, [3], axis=1)\n",
    "arr1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1e4094",
   "metadata": {},
   "source": [
    "### Index 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ebdc676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4],\n",
       "       [5, 6, 7, 8]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = np.array([[1,2,3,4],[5,6,7,8],[9,10,11,12]])\n",
    "\n",
    "l[0:2] #start~end-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85231d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 3],\n",
       "       [5, 7]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[:2,::2] #0~end-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af06b401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  3],\n",
       "       [ 9, 11]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[::2, ::2] #stride = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315b0878",
   "metadata": {},
   "source": [
    "### logical indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd3a11e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, False],\n",
       "       [False, False, False, False],\n",
       "       [ True,  True,  True,  True]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l>8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6049e1d6",
   "metadata": {},
   "source": [
    "-> index False, True 값으로 발현여부 index처리가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "851e4a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9, 10, 11, 12])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[l>8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61f9b30",
   "metadata": {},
   "source": [
    "## numpy 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0458fe21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.6, 3.2, 4.8])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "miles = np.array([1,2,3])\n",
    "miles*1.6 #기본 = element-wise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b4ae2e",
   "metadata": {},
   "source": [
    "참고: .shape == (m,n) === m by n 행렬 의미"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaef0cea",
   "metadata": {},
   "source": [
    "### 행렬곱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba4ba94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A@B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c657185",
   "metadata": {},
   "source": [
    "## Array 메소드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e426d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 6, 8])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [[1,2],[3,4],[5,6],[7,8]]\n",
    "b = np.array(a)\n",
    "\n",
    "b.sum()\n",
    "b.min()\n",
    "b.max(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53717ee4",
   "metadata": {},
   "source": [
    "-> axis는 방향을 의미,  \n",
    "axis=1: 열이 나아가는 방향  \n",
    "1vs2  \n",
    "3vs4  \n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2beff64e",
   "metadata": {},
   "source": [
    "# #1 Perceptron 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d1106538",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "\n",
    "# init setting\n",
    "data = [\n",
    "    (array([0,0,1]), 0),\n",
    "    (array([0,1,1]), 1),\n",
    "    (array([1,0,1]), 1),\n",
    "    (array([1,1,1]), 1),\n",
    "]\n",
    "\n",
    "w = random.rand(3)\n",
    "c = 0.2\n",
    "n  = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aedc738a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0] -0.09701939514609376 0\n",
      "[0 1] 0.4387605384668006 1\n",
      "[1 0] 0.4924601744987705 1\n",
      "[1 1] 1.0282401081116648 1\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "# Perceptron -> using Step activation\n",
    "\n",
    "for epoch in range(n):\n",
    "    for x,y in data:\n",
    "        z = dot(x,w)\n",
    "        \n",
    "        # Activation = Step\n",
    "        if z<0:\n",
    "            a=0\n",
    "        else:\n",
    "            a=1\n",
    "            \n",
    "        dL_dA = a-y\n",
    "        dA_dw = x\n",
    "        delta = (-1)*dL_dA*dA_dw*c\n",
    "        \n",
    "        # stochastic, 빠른 수렴 기대\n",
    "        w += delta\n",
    "        \n",
    "# Test\n",
    "for x,_ in data:\n",
    "    z = dot(x,w)\n",
    "    if z<0:\n",
    "        a=0\n",
    "    else:\n",
    "        a=1\n",
    "    print(x[:2], z, a)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc76a03",
   "metadata": {},
   "source": [
    "- Activation = Step  \n",
    "=> a = 1 or 0  \n",
    "  \n",
    "- Loss = (1/2)*(Y-A)^2  \n",
    "-> dL/dA = (A-Y)  \n",
    "-> dA/dw = x  \n",
    "=> delta = r*(A-Y)*x*(-1)  \n",
    "  \n",
    "- x에 bias term: always1 포함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b862542b",
   "metadata": {},
   "source": [
    "# Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a262a7d9",
   "metadata": {},
   "source": [
    "## tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35141989",
   "metadata": {},
   "source": [
    "ndarray의 일반화,  \n",
    "numpy와 호환가능  \n",
    "  \n",
    "+ graphic faster(GPU성능 좋음)\n",
    "+ Distribute operations(연산 분산가능)\n",
    "+ 그래프 연산 트래킹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d107f687",
   "metadata": {},
   "source": [
    "# Mechanics of Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0a7ed0",
   "metadata": {},
   "source": [
    ": 실제로 러닝을 구현하는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c827f7",
   "metadata": {},
   "source": [
    "## Learning = 파라미터 추정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e752e347",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "# pytorch 로딩\n",
    "import torch\n",
    "torch.set_printoptions(edgeitems=2, linewidth=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bd1fd98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input data\n",
    "t_c = [0.5, 14.0, 15.0, 28.0, 11.0, 8.0, 3.0, -4.0, 6.0, 13.0, 21.0] # celcius\n",
    "t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4] # F(tend to be unknown)\n",
    "\n",
    "t_c = torch.tensor(t_c)\n",
    "t_u = torch.tensor(t_u)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e9217e",
   "metadata": {},
   "source": [
    "torch.tensor() 메소드로 tensor 형태로 데이터 변형  \n",
    "  \n",
    "t_c: 정확한 Celcius 값 = y  \n",
    "t_u: 미지의 데이터값 = x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bc5796",
   "metadata": {},
   "source": [
    "### Get Predicted Value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abbe2e4",
   "metadata": {},
   "source": [
    "x 자체의 shape가 (n,1)이기 때문에,  \n",
    "w의 차원은 1,1 = 스칼라  \n",
    "그러므로 sample을 한 번에 처리해서 볼 예정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cb41cf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(t_u, w, b):\n",
    "    return t_u * w + b # m개 1차 배열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bdb04938",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(t_p, t_c):\n",
    "    return ((t_c - t_p)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3337f0de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1763.8848)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.ones((1))\n",
    "b = torch.zeros((1))\n",
    "\n",
    "t_p = model(t_u, w, b)\n",
    "loss = loss_fn(t_p, t_c)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052914ff",
   "metadata": {},
   "source": [
    "## Decrease Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8468e996",
   "metadata": {},
   "source": [
    "### parameter tuning -- stochastic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "72763488",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = 0.1\n",
    "r = 1e-2\n",
    "\n",
    "loss_rate_of_w = (loss_fn(model(t_u, w + delta, b), t_c) - loss_fn(model(t_u, w-delta, b), t_c)) / 2*delta\n",
    "w -= r*loss_rate_of_w\n",
    "\n",
    "loss_rate_of_b = (loss_fn(model(t_u,w,b+delta), t_c) - loss_fn(model(t_u, w, b-delta), t_c)) / 2*delta\n",
    "b -= r*loss_rate_of_b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46717491",
   "metadata": {},
   "source": [
    "### gradient 조정 // batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3d5d8731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4517.2964,   82.6000])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dL/dA\n",
    "def dA_fn(t_p, t_c):\n",
    "    return (2*(t_p-t_c))/t_p.size(0)\n",
    "\n",
    "# dA/dw\n",
    "def dw_fn(t_u, w, b):\n",
    "    return t_u\n",
    "    \n",
    "# dA/db\n",
    "def db_fn(t_u, w, b):\n",
    "    return 1.0\n",
    "\n",
    "def grad_fn(t_u, t_c, t_p, w, b):\n",
    "    dloss_dtp = dA_fn(t_p, t_c)\n",
    "    dloss_dw = dloss_dtp * dw_fn(t_u, w, b)\n",
    "    dloss_db = dloss_dtp * db_fn(t_u, w, b)\n",
    "    # 일률적 dw 조정\n",
    "    return torch.stack([dloss_dw.sum(), dloss_db.sum()])\n",
    "\n",
    "grad_fn(t_u, t_c, t_p, w, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8b959d",
   "metadata": {},
   "source": [
    "### Training_Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e0b1744d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(epochs, learning_rate, params, t_u, t_c):\n",
    "    for epoch in range(epochs):\n",
    "        w,b = params\n",
    "        \n",
    "        #forward\n",
    "        t_p = model(t_u, t_c, w, b)\n",
    "        loss = loss_fn(t_p, t_c)\n",
    "        \n",
    "        #backward -> get dparams\n",
    "        dparams = grad_fn(t_u, t_c, t_p, w, b)\n",
    "        #params tuning\n",
    "        params -= dparams*learning_rate\n",
    "        print('Epoch %d, Loss %f' % (epoch, float(loss)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560b1d83",
   "metadata": {},
   "source": [
    "### Fancy one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "75f8ed78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, learning_rate, params, t_u, t_c, print_params=True):\n",
    "    for epoch in range(1, n_epochs + 1): \n",
    "        t_p = model(t_u, *params) # <1>\n",
    "        loss = loss_fn(t_p, t_c)\n",
    "        grad = grad_fn(t_u, t_c, t_p, *params) # <2>\n",
    "        params = params - learning_rate * grad\n",
    "        \n",
    "        if epoch in {1, 2, 3, 10, 11, 99, 100, 4000, 5000}: \n",
    "            print('Epoch %d, Loss %f' % (epoch, float(loss))) \n",
    "            if print_params:\n",
    "                print(' Params:', params)\n",
    "                print(' Grad: ', grad) \n",
    "            if epoch in {4, 12, 101}:\n",
    "                print('...')\n",
    "        if not torch.isfinite(loss).all():\n",
    "            break  # <3>\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "015e5363",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss 1763.884766\n",
      " Params: tensor([-44.1730,  -0.8260])\n",
      " Grad:  tensor([4517.2964,   82.6000])\n",
      "Epoch 2, Loss 5802484.500000\n",
      " Params: tensor([2568.4011,   45.1637])\n",
      " Grad:  tensor([-261257.4062,   -4598.9702])\n",
      "Epoch 3, Loss 19408029696.000000\n",
      " Params: tensor([-148527.7344,   -2616.3931])\n",
      " Grad:  tensor([15109614.0000,   266155.6875])\n",
      "Epoch 10, Loss 90901105189019073810297959556841472.000000\n",
      " Params: tensor([3.2144e+17, 5.6621e+15])\n",
      " Grad:  tensor([-3.2700e+19, -5.7600e+17])\n",
      "Epoch 11, Loss inf\n",
      " Params: tensor([-1.8590e+19, -3.2746e+17])\n",
      " Grad:  tensor([1.8912e+21, 3.3313e+19])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-1.8590e+19, -3.2746e+17])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loop(\n",
    "    n_epochs = 100,\n",
    "    learning_rate = 1e-2,\n",
    "    params = torch.tensor([1.0, 0.0]),\n",
    "    t_u = t_u,\n",
    "    t_c = t_c\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e347928",
   "metadata": {},
   "source": [
    "# 학습결과 해석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5aa82a",
   "metadata": {},
   "source": [
    "## #1문제: Loss가 너무 크다\n",
    "gradient exploding..  \n",
    "= 발산하는 문제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59a49e2",
   "metadata": {},
   "source": [
    "## 해결: step을 줄인다 == 수렴기대"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "52dc7339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss 1763.884766\n",
      " Params: tensor([ 9.5483e-01, -8.2600e-04])\n",
      " Grad:  tensor([4517.2964,   82.6000])\n",
      "Epoch 2, Loss 1565.761353\n",
      " Params: tensor([ 0.9123, -0.0016])\n",
      " Grad:  tensor([4251.5220,   77.9184])\n",
      "Epoch 3, Loss 1390.265503\n",
      " Params: tensor([ 0.8723, -0.0023])\n",
      " Grad:  tensor([4001.3838,   73.5123])\n",
      "Epoch 10, Loss 611.527405\n",
      " Params: tensor([ 0.6509, -0.0065])\n",
      " Grad:  tensor([2617.3997,   49.1337])\n",
      "Epoch 11, Loss 545.011597\n",
      " Params: tensor([ 0.6263, -0.0069])\n",
      " Grad:  tensor([2463.4038,   46.4211])\n",
      "Epoch 99, Loss 29.116278\n",
      " Params: tensor([ 0.2341, -0.0165])\n",
      " Grad:  tensor([11.8088,  3.2363])\n",
      "Epoch 100, Loss 29.114819\n",
      " Params: tensor([ 0.2340, -0.0165])\n",
      " Grad:  tensor([11.1109,  3.2240])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2340, -0.0165])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loop(\n",
    "    n_epochs = 100,\n",
    "    learning_rate = 1e-5,\n",
    "    params = torch.tensor([1.0, 0.0]),\n",
    "    t_u = t_u,\n",
    "    t_c = t_c\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "26b765a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss 1763.884766\n",
      "Epoch 2, Loss 323.090515\n",
      "Epoch 3, Loss 78.929634\n",
      "Epoch 10, Loss 29.105247\n",
      "Epoch 11, Loss 29.104168\n",
      "Epoch 99, Loss 29.023582\n",
      "Epoch 100, Loss 29.022667\n",
      "Epoch 4000, Loss 25.691162\n",
      "Epoch 5000, Loss 24.907743\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2577, -1.4631])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loop(\n",
    "    n_epochs = 5000,\n",
    "    learning_rate = 1e-4,\n",
    "    params = torch.tensor([1.0, 0.0]),\n",
    "    t_u = t_u,\n",
    "    t_c = t_c,\n",
    "    print_params = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819d0f51",
   "metadata": {},
   "source": [
    "## #2문제: 파라미터별로 Gradient 차이가 너무 크다\n",
    "parameter 별로 scale이 달라서 생기는 문제  \n",
    "한 params(W)의 변화가 다음 epoch에서 다른 params(b)의 변화에 너무 큰 영향을 미치는게 문제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbea6e9",
   "metadata": {},
   "source": [
    "## 해결: input normalizing\n",
    "Why input, not parameter??  \n",
    "bias scale = 일반 수  \n",
    "params scale = x에 의해 좌우  \n",
    "  \n",
    "=> x를 표준화 -> bias와 스케일 일치, Gradient 차이 문제 해결  \n",
    "= Parameter Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f4dc8788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss 80.364342\n",
      " Params: tensor([1.7761, 0.1064])\n",
      " Grad:  tensor([-77.6140, -10.6400])\n",
      "Epoch 2, Loss 37.574913\n",
      " Params: tensor([2.0848, 0.1303])\n",
      " Grad:  tensor([-30.8623,  -2.3864])\n",
      "Epoch 3, Loss 30.871077\n",
      " Params: tensor([2.2094, 0.1217])\n",
      " Grad:  tensor([-12.4631,   0.8587])\n",
      "Epoch 10, Loss 29.030489\n",
      " Params: tensor([ 2.3232, -0.0710])\n",
      " Grad:  tensor([-0.5355,  2.9295])\n",
      "Epoch 11, Loss 28.941877\n",
      " Params: tensor([ 2.3284, -0.1003])\n",
      " Grad:  tensor([-0.5240,  2.9264])\n",
      "Epoch 99, Loss 22.214186\n",
      " Params: tensor([ 2.7508, -2.4910])\n",
      " Grad:  tensor([-0.4453,  2.5208])\n",
      "Epoch 100, Loss 22.148710\n",
      " Params: tensor([ 2.7553, -2.5162])\n",
      " Grad:  tensor([-0.4446,  2.5165])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 2.7553, -2.5162])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_un = 0.1*t_u\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 100,\n",
    "    learning_rate = 1e-2,\n",
    "    params = torch.tensor([1.0, 0.0]),\n",
    "    t_u = t_un,\n",
    "    t_c = t_c\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5f7aba79",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m params \u001b[38;5;241m=\u001b[39m training_loop(\n\u001b[1;32m      2\u001b[0m     n_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5000\u001b[39m,\n\u001b[1;32m      3\u001b[0m     learning_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-2\u001b[39m,\n\u001b[0;32m----> 4\u001b[0m     params \u001b[38;5;241m=\u001b[39m \u001b[43mparams\u001b[49m,\n\u001b[1;32m      5\u001b[0m     t_u \u001b[38;5;241m=\u001b[39m t_un,\n\u001b[1;32m      6\u001b[0m     t_c \u001b[38;5;241m=\u001b[39m t_c,\n\u001b[1;32m      7\u001b[0m     print_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m     10\u001b[0m params\n",
      "\u001b[0;31mNameError\u001b[0m: name 'params' is not defined"
     ]
    }
   ],
   "source": [
    "params = training_loop(\n",
    "    n_epochs = 5000,\n",
    "    learning_rate = 1e-2,\n",
    "    params = params,\n",
    "    t_u = t_un,\n",
    "    t_c = t_c,\n",
    "    print_params = False\n",
    ")\n",
    "\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60124443",
   "metadata": {},
   "source": [
    "### Argument Unpacking\n",
    "params = (a,b) -> fn(c, d, *params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f53b04",
   "metadata": {},
   "source": [
    "## Let's Visualize\n",
    "-> using pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c582c88",
   "metadata": {},
   "source": [
    "plt _ 의존  \n",
    ".plot() x,y 입력값에 대해 그래프 그려줌  \n",
    "-> x,y는 numpy여야한다.  \n",
    "=> tensor.numpy()로 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "896050d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pyplot \u001b[38;5;28;01mas\u001b[39;00m plt\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# after learning value\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m t_p \u001b[38;5;241m=\u001b[39m model(t_un, \u001b[38;5;241m*\u001b[39m\u001b[43mparams\u001b[49m)\n\u001b[1;32m      6\u001b[0m fig \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mfigure(dpi\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m600\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# x,y 라벨 설정\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'params' is not defined"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# after learning value\n",
    "t_p = model(t_un, *params)\n",
    "\n",
    "fig = plt.figure(dpi=600)\n",
    "# x,y 라벨 설정\n",
    "plt.xlabel(\"Temperature (F)\")\n",
    "plt.ylabel(\"Temperature (C)\")\n",
    "\n",
    "# inferenced\n",
    "plt.plot(t_u.numpy(), t_p.numpy())\n",
    "# data 'o' to make dot\n",
    "plt.plot(t_u.numpy(), t_c.numpy(), 'o')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f39d9b",
   "metadata": {},
   "source": [
    "# autograd == Pytorch cal Gradient(Back-propagation)\n",
    ": params by params  \n",
    "grad는 tensor에 프로퍼티로 저장할 수 있다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b586baa3",
   "metadata": {},
   "source": [
    "### tensor.grad 활용 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "96c9d54e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = torch.tensor([1.0, 0.0], requires_grad = True) # can tracking in Loss\n",
    "\n",
    "params.grad is None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3141724",
   "metadata": {},
   "source": [
    "### loss.backward() 활용\n",
    "-> params.grad 저장 후 알아서 핸들링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b01fd8f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4517.2969,   82.6000])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = loss_fn(model(t_u,*params), t_c)\n",
    "loss.backward()\n",
    "\n",
    "params.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a656454",
   "metadata": {},
   "source": [
    "### backward란?\n",
    "기울기계산 -> 리프노드에 기울기 쌓아(단순합) 저장  \n",
    "=> 누적계산되지 않으려면???  \n",
    "parmas.grad를 parameter tuning 이후에 지워줘야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a553f4a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0.])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params.grad.zero_() # 다음 합 = 다음 derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c88e1a2",
   "metadata": {},
   "source": [
    "## Training Loop by autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "88804b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, learning_rate, params, t_u, t_c, print_params=True):\n",
    "    for epoch in range(1, n_epochs + 1): \n",
    "        if params.grad is not None:\n",
    "            params.grad.zero_()\n",
    "        \n",
    "        t_p = model(t_u, *params) # <1>\n",
    "        loss = loss_fn(t_p, t_c)\n",
    "        \n",
    "        #grad = grad_fn(t_u, t_c, t_p, *params) # <2>\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            params -= learning_rate * params.grad\n",
    "            \n",
    "        if epoch % 500 == 0:\n",
    "            print('Epoch %d, Loss %f' % (epoch, loss))\n",
    "                \n",
    "        if not torch.isfinite(loss).all():\n",
    "            break  # <3>\n",
    "            \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "15dd2c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500, Loss 7.860115\n",
      "Epoch 1000, Loss 3.828538\n",
      "Epoch 1500, Loss 3.092191\n",
      "Epoch 2000, Loss 2.957698\n",
      "Epoch 2500, Loss 2.933134\n",
      "Epoch 3000, Loss 2.928648\n",
      "Epoch 3500, Loss 2.927830\n",
      "Epoch 4000, Loss 2.927679\n",
      "Epoch 4500, Loss 2.927652\n",
      "Epoch 5000, Loss 2.927647\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([  5.3671, -17.3012], requires_grad=True)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loop(\n",
    "    n_epochs = 5000,\n",
    "    learning_rate = 1e-2,\n",
    "    params = torch.tensor([1.0,0.0], requires_grad = True),\n",
    "    t_u = t_un,\n",
    "    t_c = t_c,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d5080e",
   "metadata": {},
   "source": [
    "## with 키워드\n",
    ": critical region에 접근할 때 사용,  \n",
    "객체의 라이프사이클(생성 >> 사용 >> 소멸)을 설계  \n",
    "with torch.no_grad():  \n",
    "-> no.grad() 안에는  \n",
    "\\__enter__  \n",
    "\\__fn__  \n",
    "\\__exit__  \n",
    "\n",
    "=> 순서에 맞게 실행  \n",
    "\n",
    "## no_grad() 함수가 의미하는 것\n",
    "requires_grad = True로 설정시 params.grad에 대한 모든 연산을 트래킹하게 설정되어있다.  \n",
    "하지만 연산이 트래킹될 필요가 없는 경우에는 grad의 연산과정을 트래킹하지 않도록 no_grad()로 설정할 수 있다.  \n",
    "일례로 단순히 gradient descent를 할 경우, 각 연산은 한 번 쓰이고 끝나므로 keep watching할 필요가 없지만,  \n",
    "optimizer를 사용하여 자동으로 additionally하게 연산을 추가해야하는 경우 해당 grad operation을 다시 들여다볼 필요가 있으므로, no_grad()가 아닌 범위에서 수행되는 것이다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491cc438",
   "metadata": {},
   "source": [
    "# Optimizers\n",
    ": operate when backward()\n",
    "\n",
    "### Optimizer.step()\n",
    "적용된 grad에 optimizer value 적용해서 처리  \n",
    "=> param 직접 바꿀 필요 없이 optimizer 적용된 값으로 조정\n",
    "=> parameter tuning을 optimizer가 알아서 처리한다는 의미\n",
    "### Optimizer.grad_zero()\n",
    "이전에 사용된 grad 초기화, clear -> with torch.no_grad(): or .grad.zero_() 같은거 안해도 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4086b5c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4517.2969,   82.6000])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "params = torch.tensor([1.0,0.0], requires_grad = True)\n",
    "learning_rate = 1e-5\n",
    "optimizer = optim.SGD([params], lr=learning_rate)\n",
    "\n",
    "t_p = model(t_u, *params)\n",
    "\n",
    "loss = loss_fn(t_p, t_c)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "params.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cf746009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-77.6140, -10.6400])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "params = torch.tensor([1.0,0.0], requires_grad = True)\n",
    "learning_rate = 1e-2\n",
    "optimizer = optim.SGD([params], lr=learning_rate)\n",
    "\n",
    "t_p = model(t_un, *params)\n",
    "\n",
    "loss = loss_fn(t_p, t_c)\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "params.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "48aa45f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, params, t_u, t_c, print_params=True):\n",
    "    for epoch in range(1, n_epochs + 1): \n",
    "        \n",
    "        t_p = model(t_u, *params) # <1>\n",
    "        loss = loss_fn(t_p, t_c)\n",
    "        \n",
    "        #grad = grad_fn(t_u, t_c, t_p, *params) # <2>\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        if epoch % 500 == 0:\n",
    "            print('Epoch %d, Loss %f' % (epoch, loss))\n",
    "            \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6fec8d7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500, Loss 7.860115\n",
      "Epoch 1000, Loss 3.828538\n",
      "Epoch 1500, Loss 3.092191\n",
      "Epoch 2000, Loss 2.957698\n",
      "Epoch 2500, Loss 2.933134\n",
      "Epoch 3000, Loss 2.928648\n",
      "Epoch 3500, Loss 2.927830\n",
      "Epoch 4000, Loss 2.927679\n",
      "Epoch 4500, Loss 2.927652\n",
      "Epoch 5000, Loss 2.927647\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([  5.3671, -17.3012], requires_grad=True)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = torch.tensor([1.0,0.0], requires_grad = True)\n",
    "learning_rate = 1e-2\n",
    "optimizer = optim.SGD([params], lr = learning_rate)\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 5000,\n",
    "    optimizer = optimizer,\n",
    "    params = params,\n",
    "    t_u = t_un,\n",
    "    t_c = t_c\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e49f03c",
   "metadata": {},
   "source": [
    "# 교차검증\n",
    ": training & validation  \n",
    "-> overfitting 되어 있는지 측정가능  \n",
    "training 결과가 validation 결과보다 많이 좋다면 overfitting된 상태  \n",
    "-> Data 늘리거나 Reg 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b34b3ac",
   "metadata": {},
   "source": [
    "### make validation set\n",
    "tensor 자체를 분리하지 않는다. (랜덤하게 추출하는 방법을 여러번 사용하기 위해서인듯)  \n",
    "-> 그 때 그 때 index tensor를 만들어서 관리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d850e319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20% 비율로 설정\n",
    "m = t_u.shape[0]\n",
    "n_val = int(m*0.2)\n",
    "\n",
    "\n",
    "shuffled_index = torch.randperm(m)\n",
    "train_index = shuffled_index[:-n_val]\n",
    "val_index = shuffled_index[-n_val:]\n",
    "\n",
    "train_t_u = t_u[train_index]\n",
    "train_t_c = t_u[train_index]\n",
    "val_t_u = t_u[val_index]\n",
    "val_t_c = t_c[val_index]\n",
    "\n",
    "train_t_un = 0.1*train_t_u\n",
    "val_t_un = 0.1*train_t_u"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67397a94",
   "metadata": {},
   "source": [
    "### training loop 업데이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d884973d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, params, train_t_u, train_t_c, val_t_u, val_t_c):\n",
    "    for epoch in range(n_epochs):\n",
    "        #각각 forwarding & get loss\n",
    "        train_p = model(train_t_u, *params)\n",
    "        train_loss = loss_fn(train_p, train_t_c)\n",
    "        val_p = model(val_t_u, *params)\n",
    "        val_loss = loss_fn(val_p, val_t_c)\n",
    "        \n",
    "        # train_loss만 학습에 사용\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch <=3 or epoch % 500 == 0:\n",
    "            print(f\"Epoch {epoch}, Training loss {train_loss.item():.4f},\"f\" Validation loss {val_loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de68be9",
   "metadata": {},
   "source": [
    "### inference 모드에서 grad 계산 방지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "51f85968",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.set_grad_enabled(False):\n",
    "    t_p = model(t_u, *params)\n",
    "    loss = loss_fn(t_p, t_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabda94c",
   "metadata": {},
   "source": [
    "# Keyword 정리\n",
    "- requires_grad = True\n",
    "- TENSOR.grad.zero_()\n",
    "- with torch.no_grad():\n",
    "- optimizer.zero_grad()\n",
    "- torch.optim as optim\n",
    "- optim.SGD([parmas], lr)\n",
    "- optimizer.step()\n",
    "- int(A*B)\n",
    "- tensor[tensor(index or bool)]\n",
    "- torch.randperm(m) 0~m index permutating"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
